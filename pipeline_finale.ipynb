{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "265cc3aa",
   "metadata": {},
   "source": [
    "# **Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2479ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from stores_module import *\n",
    "from recursive_predictions import *\n",
    "from sales_module import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9827cc5",
   "metadata": {},
   "source": [
    "# **Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30eef0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"AngeliqueFile.pkl\", \"rb\") as f:\n",
    "    transactions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ffde2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"train.csv\")\n",
    "train_set[\"date\"] = pd.to_datetime(train_set[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d787da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transac_sales.pkl\",\"rb\") as f:\n",
    "    transac_sales = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceabedd",
   "metadata": {},
   "source": [
    "# **Prediction transactions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0a5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_list = list(transactions[\"store_nbr\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "986bcca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_test = transactions.loc[transactions[\"date\"] >= \"2017-08-01\",\"date\"].to_frame()\n",
    "stores_test.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c8bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in stores_list:\n",
    "    store_df = store_data(store)\n",
    "    no_cat_list = [\"not a national event\",\"Not a Nat holiday\",\"Nope\"]\n",
    "    for col in store_df.columns:\n",
    "        for cat in no_cat_list:\n",
    "            if store_df[col].dtype == \"category\" and cat in store_df[col].cat.categories:\n",
    "                store_df[col] = rename_null_cat(store_df,col,cat)\n",
    "        if store_df[col].dtype == \"category\" and len(store_df[col].cat.categories) == 2:\n",
    "            col_binom = binom_cat_bool(store_df)\n",
    "            col_binom.binom_bool()\n",
    "            store_df.loc[:,col] = col_binom.transform()\n",
    "\n",
    "        elif store_df[col].dtype == \"category\" and len(store_df[col].cat.categories) > 2:\n",
    "            col_Encod = my_labelEncoder()\n",
    "            col_Encod.fit(store_df,col)\n",
    "            store_df[col] = col_Encod.transform(store_df,col)\n",
    "    \n",
    "    _,store_df = frame_time_of_interest(store_df,8) #To generalise we need to precise the month upstream\n",
    "    split_Lagg = SplitLagg(store_df)\n",
    "    split_Lagg.transactions_X()\n",
    "    X_df = split_Lagg.lagg_X(lags=4)\n",
    "    y_df = split_Lagg.lagg_y(lags=4)\n",
    "    X_train,y_train,X_test,y_test,test_y = split_train_test(X_df,y_df,date=\"2017-07-31\")\n",
    "    predictions_store, test_yPred = recurs_Lin_regr(X_train,y_train,X_test,test_y)\n",
    "    if \"store_nbr\" not in stores_test.columns:\n",
    "        stores_test[\"store_nbr\"] = [25] * len(y_test)\n",
    "        stores_test[\"value\"] = y_test.values\n",
    "        stores_test[\"transactions_pred\"] = predictions_store\n",
    "    else:\n",
    "        store_dict = {\"date\": y_test.index, \"store_nbr\": [store] * len(y_test), \"value\": y_test.values, \"transactions_pred\": predictions_store}\n",
    "        store_dict = pd.DataFrame(store_dict)\n",
    "        stores_test = pd.concat([stores_test, store_dict], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1362c75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 810 entries, 0 to 809\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   date               810 non-null    datetime64[ns]\n",
      " 1   store_nbr          810 non-null    int64         \n",
      " 2   value              810 non-null    int64         \n",
      " 3   transactions_pred  810 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2)\n",
      "memory usage: 25.4 KB\n"
     ]
    }
   ],
   "source": [
    "stores_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59d970",
   "metadata": {},
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c063b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_set[train_set[\"date\"] <\"2017-08-01\"].copy()\n",
    "test = train_set[train_set[\"date\"] >= \"2017-08-01\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a3a76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_train = transactions[transactions[\"date\"] < \"2017-08-01\"].copy()\n",
    "train = train.merge(transactions_train[[\"date\",\"transactions\",\"store_nbr\"]], \\\n",
    "                    on=[\"date\",\"store_nbr\"], how=\"inner\", validate=\"many_to_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7b3cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(stores_test[[\"date\",\"store_nbr\", \"transactions_pred\"]], \\\n",
    "                  on=[\"date\",\"store_nbr\"], how=\"inner\", validate=\"many_to_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb8a9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"transactions\"] = test[\"transactions_pred\"]\n",
    "test.drop(\"transactions_pred\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d822087",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.concat([train,test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85173722",
   "metadata": {},
   "source": [
    "## **Adding events and holidays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1136a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "holid_transac = transactions_cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fae029e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales.merge(holid_transac[[\"date\",\"store_nbr\",\"Local Holiday\",\"Regional Holiday\",\"Workday\",\"National Workday\", \"National Event\",\"National holiday\",\\\n",
    "                                   \"National period of holiday\",\"Transfer\"]],\\\n",
    "                                    on=[\"date\",\"store_nbr\"], how=\"inner\", validate=\"many_to_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "757e5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[\"Payday\"] = transac_sales[\"pay_day\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bab684b",
   "metadata": {},
   "source": [
    "# **Predictions looping through families and stores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f439a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_list = list(sales[\"family\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdc88150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUTOMOTIVE',\n",
       " 'BABY CARE',\n",
       " 'BEAUTY',\n",
       " 'BEVERAGES',\n",
       " 'BOOKS',\n",
       " 'BREAD/BAKERY',\n",
       " 'CELEBRATION',\n",
       " 'CLEANING',\n",
       " 'DAIRY',\n",
       " 'DELI',\n",
       " 'EGGS',\n",
       " 'FROZEN FOODS',\n",
       " 'GROCERY I',\n",
       " 'GROCERY II',\n",
       " 'HARDWARE',\n",
       " 'HOME AND KITCHEN I',\n",
       " 'HOME AND KITCHEN II',\n",
       " 'HOME APPLIANCES',\n",
       " 'HOME CARE',\n",
       " 'LADIESWEAR',\n",
       " 'LAWN AND GARDEN',\n",
       " 'LINGERIE',\n",
       " 'LIQUOR,WINE,BEER',\n",
       " 'MAGAZINES',\n",
       " 'MEATS',\n",
       " 'PERSONAL CARE',\n",
       " 'PET SUPPLIES',\n",
       " 'PLAYERS AND ELECTRONICS',\n",
       " 'POULTRY',\n",
       " 'PREPARED FOODS',\n",
       " 'PRODUCE',\n",
       " 'SCHOOL AND OFFICE SUPPLIES',\n",
       " 'SEAFOOD']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca324050",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.loc[sales[\"family\"] == \"BREAD/BAKERY\",\"family\"] = \"BREAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f286cd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUTOMOTIVE',\n",
       " 'BABY CARE',\n",
       " 'BEAUTY',\n",
       " 'BEVERAGES',\n",
       " 'BOOKS',\n",
       " 'BREAD',\n",
       " 'CELEBRATION',\n",
       " 'CLEANING',\n",
       " 'DAIRY',\n",
       " 'DELI',\n",
       " 'EGGS',\n",
       " 'FROZEN FOODS',\n",
       " 'GROCERY I',\n",
       " 'GROCERY II',\n",
       " 'HARDWARE',\n",
       " 'HOME AND KITCHEN I',\n",
       " 'HOME AND KITCHEN II',\n",
       " 'HOME APPLIANCES',\n",
       " 'HOME CARE',\n",
       " 'LADIESWEAR',\n",
       " 'LAWN AND GARDEN',\n",
       " 'LINGERIE',\n",
       " 'LIQUOR,WINE,BEER',\n",
       " 'MAGAZINES',\n",
       " 'MEATS',\n",
       " 'PERSONAL CARE',\n",
       " 'PET SUPPLIES',\n",
       " 'PLAYERS AND ELECTRONICS',\n",
       " 'POULTRY',\n",
       " 'PREPARED FOODS',\n",
       " 'PRODUCE',\n",
       " 'SCHOOL AND OFFICE SUPPLIES',\n",
       " 'SEAFOOD']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_list = list(sales[\"family\"].unique())\n",
    "items_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbf1e1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2755104 entries, 0 to 2755103\n",
      "Data columns (total 16 columns):\n",
      " #   Column                      Dtype         \n",
      "---  ------                      -----         \n",
      " 0   id                          int64         \n",
      " 1   date                        datetime64[ns]\n",
      " 2   store_nbr                   int64         \n",
      " 3   family                      object        \n",
      " 4   sales                       float64       \n",
      " 5   onpromotion                 int64         \n",
      " 6   transactions                float64       \n",
      " 7   Local Holiday               int32         \n",
      " 8   Regional Holiday            int32         \n",
      " 9   Workday                     int32         \n",
      " 10  National Workday            int32         \n",
      " 11  National Event              Int64         \n",
      " 12  National holiday            Int64         \n",
      " 13  National period of holiday  Int64         \n",
      " 14  Transfer                    int32         \n",
      " 15  Payday                      int64         \n",
      "dtypes: Int64(3), datetime64[ns](1), float64(2), int32(5), int64(4), object(1)\n",
      "memory usage: 291.6+ MB\n"
     ]
    }
   ],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "177f76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items_list:\n",
    "    item_df = family_df(family_name=item,df=sales,month=8)\n",
    "    stores_pred_df = transactions.loc[transactions[\"date\"] >= \"2017-08-01\",\"date\"].to_frame()\n",
    "    stores_pred_df = stores_pred_df.drop_duplicates(ignore_index=True)\n",
    "    for store in stores_list:\n",
    "        store_df = item_df[item_df[\"store_nbr\"] == store].copy()\n",
    "        to_be_lagged = store_df[[\"sales\",\"onpromotion\",\"transactions\",\"Payday\",\"weekday\"]].copy()\n",
    "        lagg = SplitLagg_sale(to_be_lagged,\"sales\")\n",
    "        lagg.sales_X()\n",
    "        lagg_X = lagg.lagg_X(4)\n",
    "        lagg_y = lagg.lagg_y(4)\n",
    "        cols_to_remove = list(to_be_lagged.columns)\n",
    "        store_df = store_df.drop(cols_to_remove,axis=1)\n",
    "        store_df = store_df.iloc[4:]\n",
    "        store_df = pd.concat([store_df,lagg_X,lagg_y],axis=1)\n",
    "        #split\n",
    "        X = store_df.drop(\"var1 y(t)\", axis=1)\n",
    "        y = store_df[[\"var1 y(t)\"]]\n",
    "        X_train = X.loc[:\"2017-07-31\"]\n",
    "        y_train = y.loc[:\"2017-07-31\"]\n",
    "        X_test = X.loc[\"2017-08-01\":]\n",
    "        y_test = y.loc[\"2017-08-01\":]\n",
    "        index=len(X.columns) - 4\n",
    "        test_y = X_test.iloc[:,index:]\n",
    "        if len(X_test)==0:\n",
    "            print(f\"The store {store} doesn't have any {item}\")\n",
    "            break\n",
    "        predictions, test_pred = recurs_Lin_regr(X_train,y_train,X_test,test_y)\n",
    "        if store == stores_list[0]:\n",
    "            stores_pred_df[\"store_nbr\"] = [store] * len(y_test)\n",
    "            stores_pred_df[\"value\"] = y_test.values\n",
    "            stores_pred_df[\"prediction\"] = predictions\n",
    "        else:\n",
    "            store_dict_i = {\"date\":X_test.index, \"store_nbr\":[store]*len(y_test), \"value\":y_test.shape[0],\\\n",
    "                          \"prediction\":predictions}\n",
    "            store_dict_i = pd.DataFrame(store_dict_i)\n",
    "            stores_pred_df = pd.concat([stores_pred_df, store_dict_i], ignore_index=True, axis=0)\n",
    "        with open(f\"{item}_pred.pkl\", \"wb\") as f:\n",
    "            pickle.dump(stores_test,f)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Essai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
